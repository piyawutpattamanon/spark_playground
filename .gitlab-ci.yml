stages:
  - test

pyspark_tests:
  stage: test
  # Pre-built image with Java + Python already installed
  # Eliminates ~30-60s spent on "apt-get install openjdk"
  image: apache/spark-py:v3.5.0
  when: manual
  # Cache strategy for startup time optimization:
  # - venv/: Reuses installed Python packages across runs (~40s saved)
  # - .ivy2/: Caches Spark's Java dependency cache (~30s saved)
  # Without cache: ~90-120s per run. With cache: ~15-20s on subsequent runs.
  cache:
    paths:
      - venv/
      - .ivy2/
    key:
      files:
        - requirements.txt
  before_script:
    - python -m venv venv
    - source venv/bin/activate
    - pip install -r requirements.txt
  script:
    - pytest test_pyspark_transformations.py -v --tb=short
